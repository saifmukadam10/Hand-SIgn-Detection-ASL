# Hand-SIgn-Detection-ASL
Hand Sign Detection of American Sign Language (ASL) using Machine Learning This repository showcases a project focused on hand sign detection for American Sign Language (ASL) leveraging Machine Learning techniques. It aims to bridge communication gaps by providing a seamless way to interpret ASL gestures into textual or digital outputs.

Features
1.Real-Time Hand Gesture Recognition: Utilizes OpenCV and MediaPipe for accurate hand tracking and landmark detection.
2.Convolutional Neural Network (CNN): Processes images of hand gestures to predict ASL letters accurately.
3.Extensive Dataset: Built with 700+ images for each ASL alphabet, ensuring robust model training.
4.User-Friendly GUI: Includes customizable themes (light/dark modes), an interactive ASL tutorial grid, and recent sign detection for sentence formation.
5.Single-Sign Capture Mode: Captures a single word when triggered by a key press, avoiding unintended inputs during continuous gestures.
6.Landmark Display: Visualizes detected hand landmarks alongside the predicted word for enhanced feedback.

Tech Stack
1.Programming Language: Python
2.Frameworks and Libraries: TensorFlow, OpenCV, MediaPipe
3.Machine Learning Model: Convolutional Neural Networks (CNNs)

Project Goals
This project is tailored to:

1.Provide a reliable solution for interpreting ASL gestures into text.
2.Create an educational tool for teaching ASL through an interactive and intuitive interface.
3.Assist individuals in learning or communicating via ASL using real-time hand gesture detection.
